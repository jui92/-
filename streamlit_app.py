import streamlit as st
import pandas as pd
import numpy as np
import os
import json
from openai import OpenAI
from sklearn.metrics.pairwise import cosine_similarity
import lancedb
import plotly.express as px

from dotenv import load_dotenv
load_dotenv()

# ---------------------------------------------------------
# ì„¤ì •
# ---------------------------------------------------------
OUTPUT_DIR = "output"
EMBEDDING_DIR = os.path.join(OUTPUT_DIR, "embeddings", "text")
TEXT_UNIT_FILE = os.path.join(OUTPUT_DIR, "text_units.parquet")

LLM_MODEL = "gpt-4o-mini"

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


# ---------------------------------------------------------
# Embeddings Load (LanceDB)
# ---------------------------------------------------------
@st.cache_resource
def load_embeddings_lancedb():
    if not os.path.exists(EMBEDDING_DIR):
        st.error("âŒ embeddings/text ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        st.stop()

    db = lancedb.connect(EMBEDDING_DIR)
    table_name = db.table_names()[0]
    table = db.open_table(table_name)

    df_embedding = table.to_pandas()
    df_embedding.rename(columns={"vector": "embedding"}, inplace=True)

    return df_embedding


# ---------------------------------------------------------
# text_units.parquet Load
# ---------------------------------------------------------
@st.cache_resource
def load_text_units():
    if not os.path.exists(TEXT_UNIT_FILE):
        st.error("âŒ text_units.parquet íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
    return pd.read_parquet(TEXT_UNIT_FILE)


# ---------------------------------------------------------
# Semantic Search
# ---------------------------------------------------------
def semantic_search(query, k=5):
    q_emb = client.embeddings.create(
        model="text-embedding-3-small",
        input=query
    ).data[0].embedding

    df_text = load_text_units()
    df_emb = load_embeddings_lancedb()

    df = df_text.merge(df_emb, on="id", how="inner")

    vectors = np.vstack(df["embedding"].values)
    scores = cosine_similarity([q_emb], vectors)[0]
    df["score"] = scores

    return df.sort_values("score", ascending=False).head(k)


# ---------------------------------------------------------
# ì²˜ë¶„ ì¶”ì²œ LLM
# ---------------------------------------------------------
def recommend_action(case_text):
    prompt = f"""
ë„ˆëŠ” ê°ì‚¬ ì „ë¬¸ê°€ë‹¤.

ë‹¤ìŒ ê°ì‚¬ ì‚¬ë¡€ ìš”ì•½ì„ ê¸°ë°˜ìœ¼ë¡œ,
1) ìœ„ë°˜ë‚´ìš© ìš”ì•½
2) ê´€ë ¨ ê·¼ê±° ê·œì •
3) ì²˜ë¶„ ìˆ˜ìœ„ ì¶”ì²œ(ì£¼ì˜/ê²½ê³ /ë¬¸ì±… ë“±)
4) ê·¸ ì´ìœ 

ë¥¼ ì‘ì„±í•´ë¼.

ê°ì‚¬ ìš”ì•½:
{case_text}
"""

    resp = client.chat.completions.create(
        model=LLM_MODEL,
        messages=[{"role": "user", "content": prompt}]
    )

    return resp.choices[0].message.content


# ---------------------------------------------------------
# ê²€ìƒ‰ ì„±ëŠ¥ í‰ê°€ ì§€í‘œ
# ---------------------------------------------------------
def hit_rate(results, ground_truth_ids):
    return 1 if results["id"].isin(ground_truth_ids).any() else 0


def precision_at_k(results, ground_truth_ids, k=5):
    top_k = results.head(k)
    hit = top_k["id"].isin(ground_truth_ids).sum()
    return hit / k


def recall_at_k(results, ground_truth_ids, k=5):
    top_k = results.head(k)
    relevant = top_k["id"].isin(ground_truth_ids).sum()
    return relevant / len(ground_truth_ids)


# ---------------------------------------------------------
# Streamlit UI
# ---------------------------------------------------------
st.set_page_config(page_title="ê°ì‚¬ ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰ Â· ì²˜ë¶„ ì¶”ì²œ", layout="wide")

st.title("ğŸ” ê°ì‚¬ ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰ Â· ê·¼ê±° Â· ì²˜ë¶„ ì¶”ì²œ")

tab1, tab2, tab3 = st.tabs(["ğŸ” ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰", "âš– ì²˜ë¶„ ì¶”ì²œ", "ğŸ“Š ê²€ìƒ‰ ì„±ëŠ¥ í‰ê°€"])

# TAB 1
with tab1:
    st.subheader("ğŸ” ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰")
    query = st.text_input("ê²€ìƒ‰ì–´ ì…ë ¥", placeholder="ì˜ˆ: ì˜ˆì‚° ë¶€ì ì • ì§‘í–‰")

    if st.button("ê²€ìƒ‰ ì‹¤í–‰"):
        results = semantic_search(query, k=5)
        st.success("ê²€ìƒ‰ ì™„ë£Œ!")

        for _, row in results.iterrows():
            st.markdown("---")
            st.markdown(f"### ğŸ“„ ì‚¬ë¡€ ID: `{row['id']}` | ì ìˆ˜: **{row['score']:.4f}**")
            st.write(row["text"])

# TAB 2
with tab2:
    st.subheader("âš– AI ì²˜ë¶„ ì¶”ì²œ")
    case_text = st.text_area("ì‚¬ë¡€ ë‚´ìš©", height=200)

    if st.button("ì¶”ì²œ ìƒì„±"):
        with st.spinner("AI ë¶„ì„ ì¤‘..."):
            st.write(recommend_action(case_text))

# TAB 3
with tab3:
    st.subheader("ğŸ“Š ê²€ìƒ‰ ì„±ëŠ¥ í‰ê°€")
    ground_truth = st.text_input("ì •ë‹µ ID (ì‰¼í‘œ êµ¬ë¶„)", placeholder="ì˜ˆ: 12, 55, 88")

    query_eval = st.text_input("ê²€ìƒ‰ì–´ ì…ë ¥", key="eval_query")

    if st.button("í‰ê°€ ì‹¤í–‰"):
        gt = [int(x.strip()) for x in ground_truth.split(",")]

        res = semantic_search(query_eval, k=10)

        st.write(f"Precision@5: {precision_at_k(res, gt):.3f}")
        st.write(f"Recall@5: {recall_at_k(res, gt):.3f}")
        st.write(f"HitRate: {hit_rate(res, gt)}")
